# Using MAGI-1 in ComfyUI

## Installation Guide

* First, [download and manually install ComfyUI](https://github.com/comfyanonymous/ComfyUI?tab=readme-ov-file#manual-install-windows-linux).

* Clone this repository into the *ComfyUI/custom\_nodes/MAGI-1* directory and [install the required dependencies](https://github.com/SandAI-org/MAGI-1?tab=readme-ov-file#environment-preparation).

  ðŸ“Œ To ensure ComfyUI recognizes the custom nodes, you must move `comfyui/__init__.py` to the root directory of MAGI-1.

* Download the MAGI-1 model files locally. In the MAGI-1 configuration file (e.g., `example/4.5B/4.5B_base_config.json` for the 4.5B base model), update the model weight paths to local paths. You need to update the following two fields:

  * **load**: Path to the DiT model weights
  * **vae\_pretrained**: Path to the VAE model weights

## Node Descriptions

After installation, launch ComfyUI from the ComfyUI directory:

```shell
cd ComfyUI
# If comfy-cli is installed
comfy launch
# Otherwise
python main.py
```

You can find the nodes provided by this repository in the *Add Node - Magi* menu of ComfyUI.

> Note: In newer versions of ComfyUI, nodes are displayed in the left-side NODE LIBRARY.

### Load Prompt

Loads a text prompt for subsequent text encoding.

* **prompt**: User-input text content; supports multiline input.

### T5 Text Encoder

Encodes the text prompt into textual features (Conditioning Embedding) for video generation.

* **prompt**: The descriptive input text.
* **t5\_pretrained\_path**: The absolute path to the T5 model weights, pointing to the pretrained model under `ckpt/t5`.
* **t5\_device**: Device to load and run the T5 model on; options include `"cpu"` or `"cuda:x"` (e.g., `"cuda:0"`).

### Load Image

Loads an image file from the input directory. Supports image file upload via a file selector.

* **image\_path**: Select an image file from ComfyUI's input folder. Non-image file types are automatically filtered.

### Process with MAGI

Core node for generating videos from text prompts, images, or continuing an input video. It also passes the frame rate to the downstream video saving node.

* **task\_mode**: Specifies which task to perform: *text-to-video, image-to-video, or video continuation*.
* **config\_path**: The absolute path to the model configuration file.
* **image\_path**: Path to the image or video file to be converted (absolute or relative to input directory).
* **text\_embeddings**: Textual features and masks generated by the text encoder, used as semantic guidance for video generation.
* **magi\_seed**: Random seed for reproducibility. The same seed will generate the same output. Default: 1234. Range: 0â€“100000.
* **video\_size\_h**: Height of the output video (in pixels). Must be a multiple of 16. Default: 720. Range: 16â€“14400.
* **video\_size\_w**: Width of the output video (in pixels). Must be a multiple of 16. Default: 720. Range: 16â€“14400.
* **num\_frames**: Total number of video frames, controlling the video length. Default: 96. Range: 24â€“24000. Must be a multiple of 24.
* **num\_steps**: Number of diffusion sampling steps. More steps result in higher quality but slower inference. Default: 64. Range: 4â€“240. Must be a multiple of 4.
* **fps**: Frames per second of the generated video. Affects playback speed and smoothness. Default: 24. Range: 1â€“60.

ðŸ“Œ Before execution, this node sets several distributed and memory-related environment variables to ensure stable performance in multi-GPU environments.

### Save Video

Saves the generated video sequence to a local file.

* **video**: The video tensor to be saved (a torch.Tensor object).
* **output\_path**: Full absolute path for saving the video (only `.mp4` is supported).
* **fps**: Frame rate of the video. Default: 24. Accepts integers from 1 to 60.

The video will be encoded at the specified frame rate and saved to `output_path`.

## Workflow Examples

This section provides example workflows, which can be imported via the *Load* button in the menu. In the latest version of ComfyUI, go to the top-left menu and select *Workflow - Open*.

The workflows are located in the `comfyui/workflow/` directory, and assets are in the `example/assets/` directory.

After importing a workflow, **you must manually update the file paths**.

### Text-to-Video

Corresponding workflow file: `workflow/magi_text_to_video_example.json`

### Image-to-Video

Corresponding workflow file: `workflow/magi_image_to_video_example.json`

### Video Continuation

Corresponding workflow file: `workflow/magi_video_continuation_example.json`
